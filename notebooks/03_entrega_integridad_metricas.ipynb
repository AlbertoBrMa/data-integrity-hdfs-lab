{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4f8123c0",
      "metadata": {},
      "source": [
        "# Entrega - Auditoria fsck + metricas + conclusiones\n",
        "\n",
        "Notebook de entrega sin hardcodear metricas: \n",
        "1. Lee auditorias fsck desde HDFS\n",
        "2. Carga tabla de metricas reales desde CSV\n",
        "3. Genera resumen y conclusiones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4ea7df89",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import io\n",
        "import re\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f9ddc76",
      "metadata": {},
      "source": [
        "## 1) Lectura de auditorias fsck\n",
        "\n",
        "Busca la ultima fecha disponible en `/audit/fsck` y lee los resumentes CSV.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f4c382ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DT detectada: 2026-02-04\n"
          ]
        }
      ],
      "source": [
        "NN_CONTAINER = \"namenode\"\n",
        "\n",
        "def run(cmd: str) -> str:\n",
        "    return subprocess.check_output(cmd, shell=True, text=True, stderr=subprocess.STDOUT)\n",
        "\n",
        "def hdfs_cat(path: str) -> str | None:\n",
        "    cmd = f'docker exec {NN_CONTAINER} bash -lc \"hdfs dfs -cat {path}\"'\n",
        "    try:\n",
        "        return run(cmd)\n",
        "    except subprocess.CalledProcessError:\n",
        "        return None\n",
        "\n",
        "def latest_fsck_dt() -> str | None:\n",
        "    cmd = f'docker exec {NN_CONTAINER} bash -lc \"hdfs dfs -ls /audit/fsck\"'\n",
        "    try:\n",
        "        out = run(cmd)\n",
        "    except subprocess.CalledProcessError:\n",
        "        return None\n",
        "    dts = []\n",
        "    for line in out.splitlines():\n",
        "        parts = line.split()\n",
        "        if len(parts) >= 8:\n",
        "            path = parts[-1]\n",
        "            dt = path.rsplit('/', 1)[-1]\n",
        "            if re.match(r'^\\d{4}-\\d{2}-\\d{2}$', dt):\n",
        "                dts.append(dt)\n",
        "    return sorted(dts)[-1] if dts else None\n",
        "\n",
        "DT = latest_fsck_dt()\n",
        "print('DT detectada:', DT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b5cbd397",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dt</th>\n",
              "      <th>scope</th>\n",
              "      <th>CORRUPT</th>\n",
              "      <th>MISSING</th>\n",
              "      <th>UNDER_REPLICATED</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2026-02-04</td>\n",
              "      <td>data</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>/audit/fsck/2026-02-04/fsck_data_summary.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2026-02-04</td>\n",
              "      <td>backup</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>/audit/fsck/2026-02-04/fsck_backup_summary.csv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           dt   scope  CORRUPT  MISSING  UNDER_REPLICATED  \\\n",
              "0  2026-02-04    data        0        0                 0   \n",
              "1  2026-02-04  backup        0        0                 0   \n",
              "\n",
              "                                           source  \n",
              "0    /audit/fsck/2026-02-04/fsck_data_summary.csv  \n",
              "1  /audit/fsck/2026-02-04/fsck_backup_summary.csv  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rows = []\n",
        "if DT is not None:\n",
        "    for target in [\"data\", \"backup\"]:\n",
        "        csv_path = f\"/audit/fsck/{DT}/fsck_{target}_summary.csv\"\n",
        "        raw = hdfs_cat(csv_path)\n",
        "        if raw:\n",
        "            tmp = pd.read_csv(io.StringIO(raw))\n",
        "            metric_map = {r.metric.upper(): int(r.count) for r in tmp.itertuples()}\n",
        "            rows.append({\n",
        "                \"dt\": DT,\n",
        "                \"scope\": target,\n",
        "                \"CORRUPT\": metric_map.get(\"CORRUPT\", 0),\n",
        "                \"MISSING\": metric_map.get(\"MISSING\", 0),\n",
        "                \"UNDER_REPLICATED\": metric_map.get(\"UNDER_REPLICATED\", 0),\n",
        "                \"source\": csv_path,\n",
        "            })\n",
        "\n",
        "fsck_table = pd.DataFrame(rows)\n",
        "if fsck_table.empty:\n",
        "    fsck_table = pd.DataFrame(columns=[\"dt\",\"scope\",\"CORRUPT\",\"MISSING\",\"UNDER_REPLICATED\",\"source\"])\n",
        "\n",
        "fsck_table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce39fe64",
      "metadata": {},
      "source": [
        "## 2) Generacion automatica de metricas reales\n",
        "\n",
        "Estas celdas permiten ejecutar el pipeline y generar `notebooks/output/metrics_raw.csv`\n",
        "con duracion, CPU promedio y memoria promedio medidas en tiempo real con `docker stats`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6f66bc84",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def parse_mem_to_mb(mem_usage: str) -> float:\n",
        "    left = mem_usage.split('/')[0].strip().replace(' ', '')\n",
        "    m = re.match(r'([0-9]+(?:\\.[0-9]+)?)([KMG]iB)', left)\n",
        "    if not m:\n",
        "        return 0.0\n",
        "    value = float(m.group(1))\n",
        "    unit = m.group(2)\n",
        "    if unit == 'GiB':\n",
        "        return value * 1024.0\n",
        "    if unit == 'MiB':\n",
        "        return value\n",
        "    if unit == 'KiB':\n",
        "        return value / 1024.0\n",
        "    return 0.0\n",
        "\n",
        "def sample_cluster_stats() -> tuple[float, float]:\n",
        "    cmd = \"docker stats --no-stream --format '{{.Name}},{{.CPUPerc}},{{.MemUsage}}'\"\n",
        "    out = run(cmd)\n",
        "    cpus = []\n",
        "    mems = []\n",
        "    for line in out.strip().splitlines():\n",
        "        parts = line.split(',', 2)\n",
        "        if len(parts) != 3:\n",
        "            continue\n",
        "        name, cpu, mem = parts\n",
        "        if not (name == 'namenode' or 'dnnm' in name):\n",
        "            continue\n",
        "        try:\n",
        "            cpus.append(float(cpu.replace('%', '').strip()))\n",
        "            mems.append(parse_mem_to_mb(mem))\n",
        "        except ValueError:\n",
        "            continue\n",
        "    if not cpus:\n",
        "        return (0.0, 0.0)\n",
        "    return (sum(cpus) / len(cpus), sum(mems) / len(mems))\n",
        "\n",
        "def run_phase_metric(fase: str, cmd: str, sample_interval_s: float = 1.0) -> dict:\n",
        "    print(f'[metric] running {fase}: {cmd}')\n",
        "    start = time.time()\n",
        "    proc = subprocess.Popen(cmd, shell=True, executable='/bin/bash')\n",
        "    cpu_samples = []\n",
        "    mem_samples = []\n",
        "\n",
        "    while proc.poll() is None:\n",
        "        cpu, mem = sample_cluster_stats()\n",
        "        cpu_samples.append(cpu)\n",
        "        mem_samples.append(mem)\n",
        "        time.sleep(sample_interval_s)\n",
        "\n",
        "    rc = proc.wait()\n",
        "    duration_s = round(time.time() - start, 2)\n",
        "    cpu_avg = round(sum(cpu_samples) / len(cpu_samples), 3) if cpu_samples else 0.0\n",
        "    mem_avg = round(sum(mem_samples) / len(mem_samples), 3) if mem_samples else 0.0\n",
        "    note = 'OK' if rc == 0 else f'FAILED({rc})'\n",
        "    return {\n",
        "        'fase': fase,\n",
        "        'duracion_s': duration_s,\n",
        "        'cpu_promedio_pct': cpu_avg,\n",
        "        'mem_promedio_mb': mem_avg,\n",
        "        'nota': note,\n",
        "    }\n",
        "\n",
        "def run_all_metrics(phases: list[tuple[str, str]], out_csv: Path) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for fase, cmd in phases:\n",
        "        rows.append(run_phase_metric(fase, cmd))\n",
        "    df = pd.DataFrame(rows)\n",
        "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
        "    df.to_csv(out_csv, index=False)\n",
        "    print(f'[metric] saved: {out_csv}')\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "158504ba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[metric] running ingesta_hdfs: bash scripts/20_ingest_hdfs.sh\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "bash: scripts/20_ingest_hdfs.sh: No existe el fichero o el directorio\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[metric] running fsck_auditoria: bash scripts/30_fsck_audit.sh\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "bash: scripts/30_fsck_audit.sh: No existe el fichero o el directorio\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[metric] running backup_copy: bash scripts/40_backup_copy.sh\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "bash: scripts/40_backup_copy.sh: No existe el fichero o el directorio\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[metric] running incident_simulation: bash scripts/70_incident_simulation.sh\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "bash: scripts/70_incident_simulation.sh: No existe el fichero o el directorio\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[metric] running recovery_restore: bash scripts/80_recovery_restore.sh\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "bash: scripts/80_recovery_restore.sh: No existe el fichero o el directorio\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[metric] saved: notebooks/output/metrics_raw.csv\n"
          ]
        }
      ],
      "source": [
        "RUN_BENCHMARK = True  # ejecuta y genera metrics_raw.csv\n",
        "METRICS_OUT = Path('notebooks/output/metrics_raw.csv')\n",
        "\n",
        "PHASES = [\n",
        "    ('ingesta_hdfs', 'bash scripts/20_ingest_hdfs.sh'),\n",
        "    ('fsck_auditoria', 'bash scripts/30_fsck_audit.sh'),\n",
        "    ('backup_copy', 'bash scripts/40_backup_copy.sh'),\n",
        "    ('incident_simulation', 'bash scripts/70_incident_simulation.sh'),\n",
        "    ('recovery_restore', 'bash scripts/80_recovery_restore.sh'),\n",
        "]\n",
        "\n",
        "if RUN_BENCHMARK:\n",
        "    metrics_generated = run_all_metrics(PHASES, METRICS_OUT)\n",
        "    metrics_generated\n",
        "else:\n",
        "    print('Para generar metricas reales: cambia RUN_BENCHMARK a True y ejecuta esta celda.')\n",
        "    print(f'Se esperaba archivo: {METRICS_OUT}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4462e94b",
      "metadata": {},
      "source": [
        "## 3) Tabla de metricas (tiempos/recursos)\n",
        "\n",
        "Carga `notebooks/output/metrics_raw.csv` generado por la seccion anterior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "466006d5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fase</th>\n",
              "      <th>duracion_s</th>\n",
              "      <th>cpu_promedio_pct</th>\n",
              "      <th>mem_promedio_mb</th>\n",
              "      <th>nota</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ingesta_hdfs</td>\n",
              "      <td>3.03</td>\n",
              "      <td>0.126</td>\n",
              "      <td>774.02</td>\n",
              "      <td>FAILED(127)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fsck_auditoria</td>\n",
              "      <td>3.03</td>\n",
              "      <td>0.122</td>\n",
              "      <td>774.02</td>\n",
              "      <td>FAILED(127)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>backup_copy</td>\n",
              "      <td>3.03</td>\n",
              "      <td>0.132</td>\n",
              "      <td>774.02</td>\n",
              "      <td>FAILED(127)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>incident_simulation</td>\n",
              "      <td>3.03</td>\n",
              "      <td>0.124</td>\n",
              "      <td>774.00</td>\n",
              "      <td>FAILED(127)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recovery_restore</td>\n",
              "      <td>3.03</td>\n",
              "      <td>0.120</td>\n",
              "      <td>774.40</td>\n",
              "      <td>FAILED(127)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  fase  duracion_s  cpu_promedio_pct  mem_promedio_mb  \\\n",
              "0         ingesta_hdfs        3.03             0.126           774.02   \n",
              "1       fsck_auditoria        3.03             0.122           774.02   \n",
              "2          backup_copy        3.03             0.132           774.02   \n",
              "3  incident_simulation        3.03             0.124           774.00   \n",
              "4     recovery_restore        3.03             0.120           774.40   \n",
              "\n",
              "          nota  \n",
              "0  FAILED(127)  \n",
              "1  FAILED(127)  \n",
              "2  FAILED(127)  \n",
              "3  FAILED(127)  \n",
              "4  FAILED(127)  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics_path = Path('notebooks/output/metrics_raw.csv')\n",
        "required_cols = [\"fase\", \"duracion_s\", \"cpu_promedio_pct\", \"mem_promedio_mb\"]\n",
        "\n",
        "if metrics_path.exists():\n",
        "    metrics = pd.read_csv(metrics_path)\n",
        "    missing = [c for c in required_cols if c not in metrics.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f'Faltan columnas en {metrics_path}: {missing}')\n",
        "else:\n",
        "    metrics = pd.DataFrame(columns=required_cols + [\"nota\"])\n",
        "\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "08bad0e2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metrica</th>\n",
              "      <th>valor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tiempo_total_s</td>\n",
              "      <td>15.150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cpu_max_pct</td>\n",
              "      <td>0.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mem_max_mb</td>\n",
              "      <td>774.400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          metrica    valor\n",
              "0  tiempo_total_s   15.150\n",
              "1     cpu_max_pct    0.132\n",
              "2      mem_max_mb  774.400"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if metrics.empty:\n",
        "    summary = pd.DataFrame(columns=[\"metrica\", \"valor\"])\n",
        "else:\n",
        "    summary = pd.DataFrame([\n",
        "        {\"metrica\": \"tiempo_total_s\", \"valor\": float(metrics['duracion_s'].sum())},\n",
        "        {\"metrica\": \"cpu_max_pct\", \"valor\": float(metrics['cpu_promedio_pct'].max())},\n",
        "        {\"metrica\": \"mem_max_mb\", \"valor\": float(metrics['mem_promedio_mb'].max())},\n",
        "    ])\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be2e47ad",
      "metadata": {},
      "source": [
        "## 4) Conclusiones y recomendaciones\n",
        "\n",
        "Plantilla basada en resultados reales del notebook:\n",
        "\n",
        "- Integridad: revisar `fsck_table` y confirmar valores de `CORRUPT`, `MISSING`, `UNDER_REPLICATED`.\n",
        "- Coste: usar `metrics` para identificar fase mas costosa (tiempo) y mayor carga (CPU/MEM).\n",
        "- Replicacion recomendada: justificar con trade-off coste/riesgo observado.\n",
        "- Frecuencia de auditoria: diaria/semanal segun criticidad del dato.\n",
        "\n",
        "Si ya tienes metricas y fsck correctos, puedes dejar una conclusion final breve en una celda markdown adicional.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "cae64397",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['notebooks/output/fsck_table_2026-02-04.csv',\n",
              " 'notebooks/output/metrics_raw.csv',\n",
              " 'notebooks/output/metrics_summary_2026-02-04.csv',\n",
              " 'notebooks/output/metrics_table_2026-02-04.csv']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_dir = Path('notebooks/output')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "if not fsck_table.empty:\n",
        "    fsck_table.to_csv(out_dir / f'fsck_table_{DT}.csv', index=False)\n",
        "if not metrics.empty:\n",
        "    metrics.to_csv(out_dir / f'metrics_table_{DT if DT else \"latest\"}.csv', index=False)\n",
        "if not summary.empty:\n",
        "    summary.to_csv(out_dir / f'metrics_summary_{DT if DT else \"latest\"}.csv', index=False)\n",
        "sorted(str(p) for p in out_dir.glob('*.csv'))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bigData",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
